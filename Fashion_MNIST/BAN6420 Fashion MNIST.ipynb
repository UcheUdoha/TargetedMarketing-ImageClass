{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8656079-5ed8-4fba-bf70-b5e8e5e91b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 11:07:40.662499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ca0986-425f-48cf-8f4f-4bfc65b48d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5us/step \n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2842b11f-7a7d-495f-a666-fad51fc326c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fad488c-1c4c-46bf-809b-1856b64cb42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential([     \n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),     \n",
    "    layers.MaxPooling2D((2, 2)),     \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'), \n",
    "    layers.MaxPooling2D((2, 2)),     \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'), \n",
    "    layers.Flatten(), \n",
    "    layers.Dense(64, activation='relu'), \n",
    "    layers.Dense(10) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d905bbf8-0b6e-4644-925a-14758cf37e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac103ea7-d705-40a9-808a-39f3fd4c816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 375ms/step - accuracy: 0.7386 - loss: 0.7114 - val_accuracy: 0.8662 - val_loss: 0.3818\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 208ms/step - accuracy: 0.8756 - loss: 0.3397 - val_accuracy: 0.8711 - val_loss: 0.3532\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 92ms/step - accuracy: 0.8952 - loss: 0.2858 - val_accuracy: 0.8946 - val_loss: 0.2944\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.2455 - val_accuracy: 0.9011 - val_loss: 0.2726\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 28ms/step - accuracy: 0.9155 - loss: 0.2258 - val_accuracy: 0.9017 - val_loss: 0.2671\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - accuracy: 0.9264 - loss: 0.1990 - val_accuracy: 0.9092 - val_loss: 0.2576\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - accuracy: 0.9331 - loss: 0.1782 - val_accuracy: 0.9079 - val_loss: 0.2745\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - accuracy: 0.9367 - loss: 0.1659 - val_accuracy: 0.9126 - val_loss: 0.2536\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.9444 - loss: 0.1497 - val_accuracy: 0.9060 - val_loss: 0.2800\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 26ms/step - accuracy: 0.9485 - loss: 0.1388 - val_accuracy: 0.9119 - val_loss: 0.2739\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10,validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a505c723-0b6b-4390-875d-22f8d20e536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Make predictions on test images\n",
    "test_images = test_images[..., np.newaxis] \n",
    "# Add channel dimension\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36cfecd-87f2-4390-ae86-6750e2854fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the image and prediction\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img[..., 0], cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8c0740-a221-4ec4-9648-2b175f50b7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAADnCAYAAADPTSXjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARh0lEQVR4nO3dS4je5fUH8GdyncwtN40xFxSrVhe1XkARwYZWaOsNdOOqpZtSdNFFN0JBoSvBVd2ICLqNYBBUSkiNFJvYGKQl1lti2pioncTGJGYmcWJu81+I7b/gc57J+8s4J8nns/Tb887zXn7v8WfnzOmbnJycLADAjJo10wcAADRkAEhBQwaABDRkAEhAQwaABDRkAEhAQwaABDRkAEhgzlT+R6dPny6jo6NleHi49PX1TfeZ4Lw1OTlZxsfHy4oVK8qsWbn/fdh1D2fHVK/7KTXk0dHRsnr16rN2OLjQffzxx2XVqlUzfYyQ6x7OrtZ1P6WGPDw8/J8HGxkZOTsngwvQ2NhYWb169X+uqcxc92dufHy8mv31r38Na9esWXOWTzM127ZtC/OhoaFqduWVV57l05yfpnrdT6khf/2fq0ZGRlyYcBacC/8J2HV/5qL3dXBwMKydqdc4arit3OfizLSu+9z/JxYAXCA0ZABIQEMGgAQ0ZABIYEq/1AVwvjh27FiY//73v69ma9euDWsPHTpUzfbv3x/WLliwoKfH7aq/v7/nfM6cuIXcfvvt1eyXv/xlWPuTn/wkzM9H7pABIAENGQAS0JABIAENGQAS0JABIAENGQASMPYEnFcefvjhMH/66afDfGxsrJoNDAyEtdHo0uLFi8PaiYmJatb6O9inTp0K8/nz51ez6MylfLU6sObLL78Ma//whz9Us5deeimsvfXWW8P8z3/+c5ifi9whA0ACGjIAJKAhA0ACGjIAJKAhA0ACGjIAJKAhA0AC5pCBc040S/z444+HtcuXLw/zaOa3r68vrI1mdk+cOBHWRmsOWysSW+eaNat+73Xy5MmwNtI619DQUDWbPXt2WPv666+H+T333FPNXn755bA2K3fIAJCAhgwACWjIAJCAhgwACWjIAJCAhgwACRh7As45jzzySDUbGRkJa1sjQtEqw3379sUHCyxatCjMoxGiOXPir+ojR46E+bFjx6rZ0qVLw9ro9WidK1rPGI2IlVLKJZdcEubR+sXPPvssrL3ooovCfKa4QwaABDRkAEhAQwaABDRkAEhAQwaABDRkAEhAQwaABMwhA+ecw4cPV7P58+eHta3512jW+MEHHwxrf/WrX1WzG2+8MayN1j5+8sknYe3w8HCYX3bZZdXs008/DWuj17N1rpUrV/b0uKWUMj4+HuYTExPVbNeuXWGtOWQAoEpDBoAENGQASEBDBoAENGQASEBDBoAEjD0B55xorV+0xrCU9thT5LHHHgvzhQsXVrPTp0+HtV988UU1W7NmTVj7pz/9Kcwj1157bZhv3769mo2NjYW1TzzxRDWLVmiWUsrFF18c5tFayM2bN4e1N998c5jPFHfIAJCAhgwACWjIAJCAhgwACWjIAJCAhgwACWjIAJCAOWS+FdHM4KxZ8b8X9vX19fxzo3nVUuIVcDt37gxrr7rqqp7ORNvx48d7rm19XlqficjPf/7zMH/xxRd7fuxDhw5Vs9ac8aOPPhrmIyMj1ey5554Law8ePFjN9uzZE9Y+8MAD1aw1hxx9Z5RSypw59fa1bdu2sDYrd8gAkICGDAAJaMgAkICGDAAJaMgAkICGDAAJaMgAkIA55HNMa5drK49mfv/1r3+FtVu2bKlmP/3pT8PawcHBMJ8u0ZxxywsvvBDmDz/8cM+PTWx0dLTn2tZc+8TERM+P/cknn/Rc2/L888/3XPuzn/0szBcsWFDNWvO+3//+96vZ3r17w9qhoaEwny6tvyGQlTtkAEhAQwaABDRkAEhAQwaABDRkAEhAQwaABIw9nWdaIx+RTZs2hfnWrVurWWtM5de//nVPZ+rq3//+d5hv2LChmg0PD5/t4zBF+/fvn7bHPnnyZJjPnTu3mrU+56dPn+7pTKWU8oMf/KDn2h//+Mdh/uGHH1azJUuWhLXr16+vZmvWrAlro5Gp1khU67WcPXt2Ndu3b19Ym5U7ZABIQEMGgAQ0ZABIQEMGgAQ0ZABIQEMGgAQ0ZABIwBzyOaa1Km3OnPgtffPNN6vZ+++/H9Zecskl1ay17uy+++6rZosXLw5rjx07FuaXXXZZNTtw4EBYOzY2Vs1WrlwZ1jJ9WqtAI60VpC0DAwPVrDXfGv0dgNa5duzYUc1aqz537doV5pFrr702zLdv317NPvroo7D2ySefrGZvvPFGWNv6XohWq3b5/Mwkd8gAkICGDAAJaMgAkICGDAAJaMgAkICGDAAJGHtKKFo71hprOnr0aJivW7eumkVjBKXE40fj4+NhbTTy0RoHaeXvvvtuNVu1alVYG41WtEbMmD5d1i9Ga/lKaa9fjPLWysDf/va3Pf/cP/7xj9XsrbfeCmuja6CUeLwvGmsqJR65euCBB8Labdu2hXmktX6xr6+vmp04caLnnzuT3CEDQAIaMgAkoCEDQAIaMgAkoCEDQAIaMgAkoCEDQALn9Rxya341mmMrJZ6Da9VGeWu+tTVHGXnqqafCPFqh2N/fH9bu2bOnmrVWJEY/tzWf2XqtBwcHq1lrtvrw4cPV7Msvvwxro5nv6Ey07d27t+faaAViKe3vhejzuHDhwrD2scceC/NI9NjR9VNKKe+9917PP3f58uVh/tlnn1Wz1ndGF11Xzfb62F2+f7tyhwwACWjIAJCAhgwACWjIAJCAhgwACWjIAJBA+rGnLqNLrXGZltb4RGS6fq1+7dq1Yb5v374wv+GGG6pZa/zo888/r2ZLliwJa5cuXVrNorGKUko5cuRImLfOHYk+X1988UVYu3Pnzmp2/fXX93okSrf1iy3z5s0L8x/+8IfVbNOmTWFttO6zdd1HY3atEaDWWshI6/qJRq5ao4HRuRYtWhTWtlY3tr5zIrt3765m3/nOd3p+3K7cIQNAAhoyACSgIQNAAhoyACSgIQNAAhoyACSgIQNAAunnkLvMEkfrE6eSR3ODrXN1mTV+9tlnq9kHH3wQ1q5evTrMDxw4UM1aM98TExPVbOXKlWHt+Ph4NWu9lgMDA2EerX7suoIzsmHDhmpmDrmbaOa9JfqsldL+rP7iF7+oZuvXrw9rW5/VSPR91Pqu6qJ1DURzyq055GhF4v333x/WtuaQu4j+9oE5ZAC4wGnIAJCAhgwACWjIAJCAhgwACWjIAJCAhgwACXwrc8hdZuhaM3LRnGlrn3GXfccto6Oj1eyFF14Ia6N536uuuiqsbe0OjuYGoxnlUkqZO3duNWu9T63dwpHW+zR//vyeawcHB6tZ6zm9/vrrYU7vWp/FSHT9lFLKsmXLwnzx4sU9/+zoGmntHY4+b9P5XdX6nEe7mFu10ffNLbfcEh+sIXpN+vv7w9rpnOvuwh0yACSgIQNAAhoyACSgIQNAAhoyACSgIQNAAmc09nTq1Knqr8BH6wZn8lf2I/v37w/z3bt3V7MdO3aEtXv37q1m8+bNC2tHRkaqWWst3djYWJifOHGimrVWqUXvcfRalRKPfCxatCisbb1e0VhGa/3iggULenrcUkoZGhqqZu+88843/vPWWBpfaX3Oo7GWaB1nKfGoWymlvP/++2EeidYNRtdeS5fvuZYuK0pb54rex67PKRpdaj2naP3iTHKHDAAJaMgAkICGDAAJaMgAkICGDAAJaMgAkICGDAAJnNEc8uzZs8NZ1JpPP/00zPfs2VPNjh49GtZGeWsN24cffhjm0crAaN6wlFKGh4erWWv11+HDh6tZ6zm1zhU9p2gmt5R4zeHx48fD2ksvvbSatWanW6sbo3V5rbnfgwcPVrNozriUUvbt23fGj9v6PPOV6VyP993vfjfM//nPf/b82NFsbes5RbWtudouWvPA0d8QiL4TSonP3VqD2dJlDrn1NyhmijtkAEhAQwaABDRkAEhAQwaABDRkAEhAQwaABM5o7CmycePGajY6OhofIhjVaf16erQirzWi1WV0qTVOE43EtH4lP1qDGI34lNIerYjO3Vo3GK2ta40IRSsWp3MEofV6RatBWyNm0ahX7bPV+szxldaqwi6vY2vs6bXXXuv5saMRoZboe6F1XXdZcdv6PoryXsZgv7Zq1apOeZcVilnXoLpDBoAENGQASEBDBoAENGQASEBDBoAENGQASEBDBoAEzmiY79VXX63Ooj7zzDPVumuuuSZ83Gg1XzQLXEo8nzdv3rywtjV3G83ftc4Vzai2ZgbHx8d7OlMp7dnZaNVa6/WIZqtbKzbfe++9atZa3dg6V6Q1Hx2tQ+zv7+/5sWur5aL3lv9qrQLtMv/auv62b99ezebOnRvWdvmsTqfoXK31i1HeZR78H//4R5gvX748zKPvo9b71FrpOlPcIQNAAhoyACSgIQNAAhoyACSgIQNAAhoyACRwRr+zftNNN5WRkZFvzN54441q3dtvvx0+7ubNm8/kGP8j+vX21mjSkiVLes4XLlwY1kajPK3RpQMHDlSzHTt2hLWtX+cfGxurZq3xh7feequaXXfddWHt5ZdfXs1eeeWVsDZaR1lKt9Vz0djGihUrwtratVBKfbwp69q3bFrjNF3Gi1qrHQ8ePFjNBgYGwtrWmsTp0rp2u4hGzLqsm3zxxRfDPPrOKKWUv/3tb9Ws9Z1w6NChMJ8p7pABIAENGQAS0JABIAENGQAS0JABIAENGQAS0JABIIEzmkNetGhRdfby0Ucf7fkQ0Wzm1q1bw9poLvcvf/lLWLt79+4w//vf/17NorV9pcSzxq2ZwWiGrjU7/b3vfS/M77jjjmp25513hrWtdYS9uvfee8P8o48+CvOlS5dWs2hWuJR4Vr01Czt//vxqdvXVV3/jP4/mwPmv1hzpsWPHen7saL1iKfHce/SelxLPOLdWRrb+PkGX2i7fR5Euc9et79/W3zZYt25dNWs9p9Ys+kxxhwwACWjIAJCAhgwACWjIAJCAhgwACWjIAJCAhgwACZzRHPJ0GRoaqmY/+tGPwtoof+ihh3o+E9+el156aaaP8K3pssf3QtKa9+0y/9rahRvNOLfO1Zo1jkSz16257NbcbZS3aqMZ5tb8c7Q3fsuWLWFtbZZ/KlrPaWJioufHnk7ukAEgAQ0ZABLQkAEgAQ0ZABLQkAEgAQ0ZABJIMfYE8P/NnTs3zAcGBqpZtM61lFJ+85vfhPnGjRurWWtcpjWe1KsuY02ldFvtGI2YtZ7v4cOHq9maNWvC2rvvvjvMf/e731Wz1vhZtGJzJrlDBoAENGQASEBDBoAENGQASEBDBoAENGQASEBDBoAEzCED6Rw9ejTMoznT1gzziRMnwvziiy+uZjt37gxrr7jiimrWZWXkdGrNKEczzq3XOlp1uWzZsrD2oosuCvNIaz56z549PT/2dHKHDAAJaMgAkICGDAAJaMgAkICGDAAJaMgAkICxJyCd2267Lcy3bNlSzfr7+8Paq6++Osw/+OCDMOfbsWvXrjAfHh6uZq31ijfffHNPZ5pu7pABIAENGQAS0JABIAENGQAS0JABIAENGQAS0JABIAFzyEA6rTnRiYmJajZv3rywtrWajxxaazKjWePjx4+HtYODgz2dabr5ZAJAAhoyACSgIQNAAhoyACSgIQNAAhoyACRg7AlIZ+XKlWF+ww03VLPW+sUuIy8nT54M89mzZ1ezycnJnn/uuSp6ztFrVUopV155ZZjfdddd1ezzzz8Pa2+99dYwnynukAEgAQ0ZABLQkAEgAQ0ZABLQkAEgAQ0ZABKY0tjT17+6PjY2Nq2HgfPd19fQuTACM5PX/ZEjR8L81KlT1aw1mtR6Pl0e29jT/+oy9hS9D6XE26Ba79PRo0er2XR83qd63U+pIY+Pj5dSSlm9enXHYwGlfHVNLVy4cKaPETpfr/sVK1bM9BGYYZs2bZqRn9u67vsmp/CvbadPny6jo6NleHi49PX1ndUDwoVkcnKyjI+PlxUrVqTfy+u6h7Njqtf9lBoyADC9cv8rOgBcIDRkAEhAQwaABDRkAEhAQwaABDRkAEhAQwaABP4PbtkanFCFuSsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first 2 test images with predictions\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "plt.figure(figsize=(6,3))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plot_image(i, predictions, test_labels, test_images)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94869f27-20ea-4319-915d-18e38704bc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
